{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import shutil\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pysam\n",
    "\n",
    "# rpy2 imports\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri, r, Formula\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.vectors import StrVector, DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_Snords/Create_counts/output\"\n",
    "working_dir = \"/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_Snords\"\n",
    "os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable automatic conversion between pandas and R dataframes\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary R packages\n",
    "dexseq = importr('DEXSeq')\n",
    "deseq2 = importr('DESeq2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dexseq_annotation():\n",
    "    \"\"\"\n",
    "    Create DEXSeq-formatted GFF file from the original annotation\n",
    "    \"\"\"\n",
    "    input_gff = \"DATA/gencode.v31.basic.annotation.gff\"\n",
    "    output_gff = \"DATA/gencode.v31.basic.annotation.DEXSeq.gff\"\n",
    "    \n",
    "    # Path to the DEXSeq preparation script\n",
    "    dexseq_script = \"/home/kubacki.michal/.conda/envs/jupyter_nb/lib/R/library/DEXSeq/python_scripts/dexseq_prepare_annotation.py\"\n",
    "    \n",
    "    # Run the preparation script\n",
    "    cmd = f\"python {dexseq_script} {input_gff} {output_gff}\"\n",
    "    print(f\"Running command: {cmd}\")\n",
    "    return_code = os.system(cmd)\n",
    "    \n",
    "    if return_code == 0:\n",
    "        print(\"Successfully created DEXSeq annotation file\")\n",
    "        return output_gff\n",
    "    else:\n",
    "        print(\"Failed to create DEXSeq annotation file\")\n",
    "        return None\n",
    "\n",
    "# Then modify your create_dexseq_dataset function to use the DEXSeq-formatted GFF\n",
    "def create_dexseq_dataset(sample_info, processed_files, dexseq):\n",
    "    \"\"\"\n",
    "    Create DEXSeqDataSet with proper formatting\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure we have the DEXSeq-formatted GFF file\n",
    "        dexseq_gff = \"DATA/gencode.v31.basic.annotation.DEXSeq.gff\"\n",
    "        if not os.path.exists(dexseq_gff):\n",
    "            dexseq_gff = prepare_dexseq_annotation()\n",
    "            if not dexseq_gff:\n",
    "                raise ValueError(\"Failed to create DEXSeq annotation file\")\n",
    "        \n",
    "        # Prepare sample data\n",
    "        sample_data = pd.DataFrame({\n",
    "            'sample': sample_info['sample'],\n",
    "            'condition': sample_info['condition']\n",
    "        })\n",
    "        \n",
    "        print(\"\\nSample data:\")\n",
    "        print(sample_data)\n",
    "        \n",
    "        # Convert to R objects\n",
    "        with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "            sample_data_r = ro.conversion.py2rpy(sample_data)\n",
    "        \n",
    "        # Create DEXSeqDataSet using the DEXSeq-formatted GFF\n",
    "        dxd = dexseq.DEXSeqDataSetFromHTSeq(\n",
    "            countfiles=ro.StrVector(processed_files),\n",
    "            sampleData=sample_data_r,\n",
    "            design=Formula('~ sample + exon + condition:exon'),\n",
    "            flattenedfile=dexseq_gff  # Use the DEXSeq-formatted GFF\n",
    "        )\n",
    "        \n",
    "        return dxd\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating DEXSeq dataset: {str(e)}\")\n",
    "        print(\"\\nChecking processed files:\")\n",
    "        for f in processed_files:\n",
    "            print(f\"\\nFile: {os.path.basename(f)}\")\n",
    "            with open(f, 'r') as file:\n",
    "                print(file.read(500))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dexseq_gff_features():\n",
    "    \"\"\"\n",
    "    Extract features from DEXSeq-formatted GFF file\n",
    "    \"\"\"\n",
    "    gff_features = set()\n",
    "    dexseq_gff = \"DATA/gencode.v31.basic.annotation.DEXSeq.gff\"\n",
    "    \n",
    "    # Ensure DEXSeq GFF exists\n",
    "    if not os.path.exists(dexseq_gff):\n",
    "        print(\"Creating DEXSeq annotation file...\")\n",
    "        dexseq_gff = prepare_dexseq_annotation()\n",
    "        if not dexseq_gff:\n",
    "            raise ValueError(\"Failed to create DEXSeq annotation file\")\n",
    "    \n",
    "    # Read features from DEXSeq-formatted GFF\n",
    "    with open(dexseq_gff, 'r') as f:\n",
    "        for line in f:\n",
    "            if 'exonic_part' in line:\n",
    "                fields = line.strip().split('\\t')\n",
    "                attrs = dict(item.strip().split(' ', 1) for item in fields[8].strip().split(';'))\n",
    "                gene_id = attrs['gene_id'].strip('\"')\n",
    "                exon_num = attrs['exonic_part_number'].strip('\"')\n",
    "                feature_id = f\"{gene_id}:E{exon_num}\"\n",
    "                gff_features.add(feature_id)\n",
    "    return gff_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DEXSeq GFF features...\n",
      "Found 405499 features in DEXSeq GFF\n",
      "\n",
      "Found 9 count files\n",
      "\n",
      "Sample count file content:\n",
      "\"ENSG00000000003.14\":\"001\"\t98\n",
      "\"ENSG00000000003.14\":\"002\"\t1033\n",
      "\"ENSG00000000003.14\":\"003\"\t342\n",
      "\"ENSG00000000003.14\":\"004\"\t4\n",
      "\"ENSG00000000003.14\":\"005\"\t303\n",
      "\"ENSG00000000003.14\":\"006\"\t288\n",
      "\"ENSG00000000003.14\":\"007\"\t283\n",
      "\"ENSG00000000003.14\":\"008\"\t220\n",
      "\"ENSG00000000003.14\":\"009\"\t384\n",
      "\"ENSG00000000003.14\":\"010\"\t256\n",
      "\"ENSG00000000003.14\":\"011\"\t9\n",
      "\"ENSG00000000003.14\":\"012\"\t8\n",
      "\"ENSG00000000005.6\":\"001\"\t8\n",
      "\"ENSG00000000005.6\":\"002\"\t10\n",
      "\"ENSG00000000005.6\":\"003\"\t12\n",
      "\"ENSG00000000005.6\":\"004\"\t8\n",
      "\"ENSG00000000005.6\":\n",
      "\n",
      "Processed ND1_2.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t98\n",
      "ENSG00000000003.14:E002\t1033\n",
      "ENSG00000000003.14:E003\t342\n",
      "ENSG00000000003.14:E004\t4\n",
      "ENSG00000000003.14:E005\t303\n",
      "\n",
      "Verification of processed_ND1_2.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed PW1_3.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t164\n",
      "ENSG00000000003.14:E002\t1985\n",
      "ENSG00000000003.14:E003\t701\n",
      "ENSG00000000003.14:E004\t4\n",
      "ENSG00000000003.14:E005\t580\n",
      "\n",
      "Verification of processed_PW1_3.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed EDO_1.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t107\n",
      "ENSG00000000003.14:E002\t900\n",
      "ENSG00000000003.14:E003\t340\n",
      "ENSG00000000003.14:E004\t1\n",
      "ENSG00000000003.14:E005\t278\n",
      "\n",
      "Verification of processed_EDO_1.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed EDO_2.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t118\n",
      "ENSG00000000003.14:E002\t1083\n",
      "ENSG00000000003.14:E003\t386\n",
      "ENSG00000000003.14:E004\t2\n",
      "ENSG00000000003.14:E005\t313\n",
      "\n",
      "Verification of processed_EDO_2.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed PW1_2.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t160\n",
      "ENSG00000000003.14:E002\t2325\n",
      "ENSG00000000003.14:E003\t823\n",
      "ENSG00000000003.14:E004\t5\n",
      "ENSG00000000003.14:E005\t657\n",
      "\n",
      "Verification of processed_PW1_2.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed EDO_3.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t71\n",
      "ENSG00000000003.14:E002\t622\n",
      "ENSG00000000003.14:E003\t220\n",
      "ENSG00000000003.14:E004\t1\n",
      "ENSG00000000003.14:E005\t165\n",
      "\n",
      "Verification of processed_EDO_3.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed ND1_3.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t87\n",
      "ENSG00000000003.14:E002\t878\n",
      "ENSG00000000003.14:E003\t326\n",
      "ENSG00000000003.14:E004\t0\n",
      "ENSG00000000003.14:E005\t271\n",
      "\n",
      "Verification of processed_ND1_3.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed ND1_1.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t68\n",
      "ENSG00000000003.14:E002\t778\n",
      "ENSG00000000003.14:E003\t244\n",
      "ENSG00000000003.14:E004\t1\n",
      "ENSG00000000003.14:E005\t205\n",
      "\n",
      "Verification of processed_ND1_1.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Processed PW1_1.dexeq_counts\n",
      "Features written: 405499\n",
      "First few lines:\n",
      "ENSG00000000003.14:E001\t96\n",
      "ENSG00000000003.14:E002\t1243\n",
      "ENSG00000000003.14:E003\t417\n",
      "ENSG00000000003.14:E004\t2\n",
      "ENSG00000000003.14:E005\t358\n",
      "\n",
      "Verification of processed_PW1_1.dexeq_counts:\n",
      "Total features in file: 405499\n",
      "Missing features: 0\n",
      "Extra features: 0\n",
      "\n",
      "Final sample information:\n",
      "  sample condition\n",
      "0  EDO_1       EDO\n",
      "1  EDO_2       EDO\n",
      "2  EDO_3       EDO\n",
      "3  ND1_1       ND1\n",
      "4  ND1_2       ND1\n",
      "5  ND1_3       ND1\n",
      "\n",
      "Processed files for DEXSeq:\n",
      "- processed_ND1_2.dexeq_counts\n",
      "- processed_EDO_1.dexeq_counts\n",
      "- processed_EDO_2.dexeq_counts\n",
      "- processed_EDO_3.dexeq_counts\n",
      "- processed_ND1_3.dexeq_counts\n",
      "- processed_ND1_1.dexeq_counts\n",
      "\n",
      "Sample data:\n",
      "  sample condition\n",
      "0  EDO_1       EDO\n",
      "1  EDO_2       EDO\n",
      "2  EDO_3       EDO\n",
      "3  ND1_1       ND1\n",
      "4  ND1_2       ND1\n",
      "5  ND1_3       ND1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in (function (countfiles, sampleData, design = ~sample + exon +  : \n",
      "  Count files do not correspond to the flattened annotation file\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating DEXSeq dataset: Error in (function (countfiles, sampleData, design = ~sample + exon +  : \n",
      "  Count files do not correspond to the flattened annotation file\n",
      "\n",
      "\n",
      "Checking processed files:\n",
      "\n",
      "File: processed_ND1_2.dexeq_counts\n",
      "ENSG00000000003.14:E001\t98\n",
      "ENSG00000000003.14:E002\t1033\n",
      "ENSG00000000003.14:E003\t342\n",
      "ENSG00000000003.14:E004\t4\n",
      "ENSG00000000003.14:E005\t303\n",
      "ENSG00000000003.14:E006\t288\n",
      "ENSG00000000003.14:E007\t283\n",
      "ENSG00000000003.14:E008\t220\n",
      "ENSG00000000003.14:E009\t384\n",
      "ENSG00000000003.14:E010\t256\n",
      "ENSG00000000003.14:E011\t9\n",
      "ENSG00000000003.14:E012\t8\n",
      "ENSG00000000005.6:E001\t8\n",
      "ENSG00000000005.6:E002\t10\n",
      "ENSG00000000005.6:E003\t12\n",
      "ENSG00000000005.6:E004\t8\n",
      "ENSG00000000005.6:E005\t10\n",
      "ENSG00000000005.6:E006\t7\n",
      "ENSG00000000005.6\n",
      "\n",
      "File: processed_EDO_1.dexeq_counts\n",
      "ENSG00000000003.14:E001\t107\n",
      "ENSG00000000003.14:E002\t900\n",
      "ENSG00000000003.14:E003\t340\n",
      "ENSG00000000003.14:E004\t1\n",
      "ENSG00000000003.14:E005\t278\n",
      "ENSG00000000003.14:E006\t246\n",
      "ENSG00000000003.14:E007\t262\n",
      "ENSG00000000003.14:E008\t196\n",
      "ENSG00000000003.14:E009\t342\n",
      "ENSG00000000003.14:E010\t233\n",
      "ENSG00000000003.14:E011\t6\n",
      "ENSG00000000003.14:E012\t5\n",
      "ENSG00000000005.6:E001\t19\n",
      "ENSG00000000005.6:E002\t19\n",
      "ENSG00000000005.6:E003\t26\n",
      "ENSG00000000005.6:E004\t29\n",
      "ENSG00000000005.6:E005\t39\n",
      "ENSG00000000005.6:E006\t23\n",
      "ENSG0000000000\n",
      "\n",
      "File: processed_EDO_2.dexeq_counts\n",
      "ENSG00000000003.14:E001\t118\n",
      "ENSG00000000003.14:E002\t1083\n",
      "ENSG00000000003.14:E003\t386\n",
      "ENSG00000000003.14:E004\t2\n",
      "ENSG00000000003.14:E005\t313\n",
      "ENSG00000000003.14:E006\t264\n",
      "ENSG00000000003.14:E007\t297\n",
      "ENSG00000000003.14:E008\t202\n",
      "ENSG00000000003.14:E009\t393\n",
      "ENSG00000000003.14:E010\t265\n",
      "ENSG00000000003.14:E011\t7\n",
      "ENSG00000000003.14:E012\t7\n",
      "ENSG00000000005.6:E001\t19\n",
      "ENSG00000000005.6:E002\t23\n",
      "ENSG00000000005.6:E003\t30\n",
      "ENSG00000000005.6:E004\t25\n",
      "ENSG00000000005.6:E005\t24\n",
      "ENSG00000000005.6:E006\t13\n",
      "ENSG000000000\n",
      "\n",
      "File: processed_EDO_3.dexeq_counts\n",
      "ENSG00000000003.14:E001\t71\n",
      "ENSG00000000003.14:E002\t622\n",
      "ENSG00000000003.14:E003\t220\n",
      "ENSG00000000003.14:E004\t1\n",
      "ENSG00000000003.14:E005\t165\n",
      "ENSG00000000003.14:E006\t158\n",
      "ENSG00000000003.14:E007\t153\n",
      "ENSG00000000003.14:E008\t116\n",
      "ENSG00000000003.14:E009\t247\n",
      "ENSG00000000003.14:E010\t162\n",
      "ENSG00000000003.14:E011\t5\n",
      "ENSG00000000003.14:E012\t6\n",
      "ENSG00000000005.6:E001\t8\n",
      "ENSG00000000005.6:E002\t11\n",
      "ENSG00000000005.6:E003\t12\n",
      "ENSG00000000005.6:E004\t14\n",
      "ENSG00000000005.6:E005\t18\n",
      "ENSG00000000005.6:E006\t14\n",
      "ENSG00000000005.\n",
      "\n",
      "File: processed_ND1_3.dexeq_counts\n",
      "ENSG00000000003.14:E001\t87\n",
      "ENSG00000000003.14:E002\t878\n",
      "ENSG00000000003.14:E003\t326\n",
      "ENSG00000000003.14:E004\t0\n",
      "ENSG00000000003.14:E005\t271\n",
      "ENSG00000000003.14:E006\t272\n",
      "ENSG00000000003.14:E007\t287\n",
      "ENSG00000000003.14:E008\t178\n",
      "ENSG00000000003.14:E009\t349\n",
      "ENSG00000000003.14:E010\t252\n",
      "ENSG00000000003.14:E011\t9\n",
      "ENSG00000000003.14:E012\t8\n",
      "ENSG00000000005.6:E001\t4\n",
      "ENSG00000000005.6:E002\t7\n",
      "ENSG00000000005.6:E003\t17\n",
      "ENSG00000000005.6:E004\t19\n",
      "ENSG00000000005.6:E005\t17\n",
      "ENSG00000000005.6:E006\t7\n",
      "ENSG00000000005.6:\n",
      "\n",
      "File: processed_ND1_1.dexeq_counts\n",
      "ENSG00000000003.14:E001\t68\n",
      "ENSG00000000003.14:E002\t778\n",
      "ENSG00000000003.14:E003\t244\n",
      "ENSG00000000003.14:E004\t1\n",
      "ENSG00000000003.14:E005\t205\n",
      "ENSG00000000003.14:E006\t191\n",
      "ENSG00000000003.14:E007\t222\n",
      "ENSG00000000003.14:E008\t160\n",
      "ENSG00000000003.14:E009\t308\n",
      "ENSG00000000003.14:E010\t225\n",
      "ENSG00000000003.14:E011\t12\n",
      "ENSG00000000003.14:E012\t8\n",
      "ENSG00000000005.6:E001\t3\n",
      "ENSG00000000005.6:E002\t3\n",
      "ENSG00000000005.6:E003\t5\n",
      "ENSG00000000005.6:E004\t5\n",
      "ENSG00000000005.6:E005\t7\n",
      "ENSG00000000005.6:E006\t6\n",
      "ENSG00000000005.6:E0\n",
      "\n",
      "Failed to create DEXSeq dataset: Error in (function (countfiles, sampleData, design = ~sample + exon +  : \n",
      "  Count files do not correspond to the flattened annotation file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_count_file(file_path, gff_features):\n",
    "    \"\"\"\n",
    "    Process DEXSeq count file to match the GFF feature format\n",
    "    \"\"\"\n",
    "    output_dir = os.path.dirname(file_path)\n",
    "    basename = os.path.basename(file_path)\n",
    "    output_path = os.path.join(output_dir, f\"processed_{basename}\")\n",
    "    \n",
    "    try:\n",
    "        # Create ordered dictionary of gff features\n",
    "        gff_feature_dict = {feature: True for feature in sorted(gff_features)}\n",
    "        \n",
    "        # Read and process file\n",
    "        count_dict = {}\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if not line.startswith('_'):  # Skip special entries\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) == 2:\n",
    "                        feature_id, count = parts\n",
    "                        # Remove quotes and split feature ID\n",
    "                        feature_id = feature_id.strip('\"')\n",
    "                        if '\":\"' in feature_id:\n",
    "                            gene_id, exon_num = feature_id.split('\":\"')\n",
    "                            exon_num = exon_num.strip('\"')\n",
    "                            # Format to match GFF style\n",
    "                            feature_id = f\"{gene_id}:E{exon_num}\"\n",
    "                            \n",
    "                            # Only keep features that exist in GFF\n",
    "                            if feature_id in gff_feature_dict:\n",
    "                                count_dict[feature_id] = int(count)\n",
    "        \n",
    "        # Create output with all GFF features (using 0 for missing counts)\n",
    "        with open(output_path, 'w') as f:\n",
    "            for feature in gff_feature_dict:\n",
    "                count = count_dict.get(feature, 0)\n",
    "                f.write(f\"{feature}\\t{count}\\n\")\n",
    "        \n",
    "        print(f\"\\nProcessed {basename}\")\n",
    "        print(f\"Features written: {len(gff_feature_dict)}\")\n",
    "        \n",
    "        # Verify file contents\n",
    "        with open(output_path, 'r') as f:\n",
    "            first_lines = [next(f) for _ in range(5)]\n",
    "        print(\"First few lines:\")\n",
    "        for line in first_lines:\n",
    "            print(line.strip())\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {basename}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def verify_processed_file(file_path, gff_features):\n",
    "    \"\"\"\n",
    "    Verify that a processed file matches GFF features exactly\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_features = set()\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                feature_id = line.strip().split('\\t')[0]\n",
    "                file_features.add(feature_id)\n",
    "        \n",
    "        missing_features = gff_features - file_features\n",
    "        extra_features = file_features - gff_features\n",
    "        \n",
    "        print(f\"\\nVerification of {os.path.basename(file_path)}:\")\n",
    "        print(f\"Total features in file: {len(file_features)}\")\n",
    "        print(f\"Missing features: {len(missing_features)}\")\n",
    "        print(f\"Extra features: {len(extra_features)}\")\n",
    "        \n",
    "        return len(missing_features) == 0 and len(extra_features) == 0\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying {file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    # Set up paths\n",
    "    data_dir = \"/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_Snords/Create_counts/output\"\n",
    "    working_dir = \"/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_Snords\"\n",
    "    os.chdir(working_dir)\n",
    "    \n",
    "    # First, ensure we have DEXSeq-formatted GFF\n",
    "    dexseq_gff = \"DATA/gencode.v31.basic.annotation.DEXSeq.gff\"\n",
    "    if not os.path.exists(dexseq_gff):\n",
    "        prepare_dexseq_annotation()\n",
    "    \n",
    "    # Get features from DEXSeq-formatted GFF\n",
    "    print(\"Loading DEXSeq GFF features...\")\n",
    "    gff_features = get_dexseq_gff_features()\n",
    "    print(f\"Found {len(gff_features)} features in DEXSeq GFF\")\n",
    "    \n",
    "    # Get count files (note the extension should match your files)\n",
    "    count_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) \n",
    "                  if f.endswith('.dexeq_counts')]\n",
    "    print(f\"\\nFound {len(count_files)} count files\")\n",
    "    \n",
    "    # Print sample of count file content\n",
    "    if count_files:\n",
    "        print(\"\\nSample count file content:\")\n",
    "        with open(count_files[0], 'r') as f:\n",
    "            print(f.read(500))\n",
    "    \n",
    "    # Process files\n",
    "    processed_files = []\n",
    "    for file in count_files:\n",
    "        processed_file = process_count_file(file, gff_features)\n",
    "        if processed_file and verify_processed_file(processed_file, gff_features):\n",
    "            processed_files.append(processed_file)\n",
    "    \n",
    "    if not processed_files:\n",
    "        print(\"No files were processed successfully\")\n",
    "        return\n",
    "    \n",
    "    # Create sample info (EDO and ND1 only)\n",
    "    edo_nd1_samples = pd.DataFrame([\n",
    "        {'sample': os.path.basename(f).replace('.dexeq_counts', '').replace('processed_', ''),\n",
    "         'condition': 'EDO' if 'EDO' in f else 'ND1'}\n",
    "        for f in processed_files\n",
    "        if 'EDO' in f or 'ND1' in f\n",
    "    ])\n",
    "    \n",
    "    # Sort samples to ensure consistent order\n",
    "    edo_nd1_samples = edo_nd1_samples.sort_values('sample').reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nFinal sample information:\")\n",
    "    print(edo_nd1_samples)\n",
    "    \n",
    "    # Create DEXSeq dataset\n",
    "    try:\n",
    "        filtered_files = [f for f in processed_files \n",
    "                         if any(s in f for s in edo_nd1_samples['sample'])]\n",
    "        \n",
    "        print(\"\\nProcessed files for DEXSeq:\")\n",
    "        for f in filtered_files:\n",
    "            print(f\"- {os.path.basename(f)}\")\n",
    "        \n",
    "        dxd = create_dexseq_dataset(edo_nd1_samples, filtered_files, dexseq)\n",
    "        print(\"Successfully created DEXSeq dataset!\")\n",
    "        return dxd\n",
    "    except Exception as e:\n",
    "        print(f\"\\nFailed to create DEXSeq dataset: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable automatic conversion between pandas and R dataframes\n",
    "    pandas2ri.activate()\n",
    "    \n",
    "    # Run the analysis\n",
    "    dxd = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
