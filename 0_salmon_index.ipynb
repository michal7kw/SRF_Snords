{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import gzip\n",
    "import shutil\n",
    "from typing import Optional, Tuple\n",
    "import urllib.request\n",
    "import logging\n",
    "import glob\n",
    "import time\n",
    "import signal\n",
    "from datetime import datetime\n",
    "\n",
    "class SalmonIndexBuilder:\n",
    "    def __init__(self, work_dir: str, gencode_version: str = \"v38\", genome: str = \"human\"):\n",
    "        self.work_dir = work_dir\n",
    "        self.gencode_version = gencode_version\n",
    "        self.genome = genome.lower()\n",
    "        \n",
    "        os.makedirs(work_dir, exist_ok=True)\n",
    "        \n",
    "        # Set up logging with timestamps and file output\n",
    "        log_file = os.path.join(work_dir, f\"salmon_index_build_{datetime.now():%Y%m%d_%H%M%S}.log\")\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "        self.fasta_gz = os.path.join(work_dir, f\"gencode.{gencode_version}.transcripts.fa.gz\")\n",
    "        self.fasta = self.fasta_gz.replace('.gz', '')\n",
    "        self.index_dir = os.path.join(work_dir, f\"salmon_index_{gencode_version}\")\n",
    "\n",
    "    def check_disk_space(self, required_gb: int = 50) -> None:\n",
    "        \"\"\"Check if there's enough disk space available.\"\"\"\n",
    "        stats = os.statvfs(self.work_dir)\n",
    "        available_gb = (stats.f_bavail * stats.f_frsize) / (1024**3)\n",
    "        \n",
    "        if available_gb < required_gb:\n",
    "            raise RuntimeError(\n",
    "                f\"Insufficient disk space. Available: {available_gb:.1f}GB, Required: {required_gb}GB\"\n",
    "            )\n",
    "\n",
    "    def download_transcriptome(self) -> None:\n",
    "        if os.path.exists(self.fasta_gz):\n",
    "            self.logger.info(f\"Transcriptome file already exists: {self.fasta_gz}\")\n",
    "            return\n",
    "\n",
    "        base_url = \"https://ftp.ebi.ac.uk/pub/databases/gencode\"\n",
    "        species = \"Gencode_human\" if self.genome == \"human\" else \"Gencode_mouse\"\n",
    "        filename = f\"gencode.{self.gencode_version}.transcripts.fa.gz\"\n",
    "        url = f\"{base_url}/{species}/release_{self.gencode_version.replace('v', '')}/{filename}\"\n",
    "\n",
    "        self.logger.info(f\"Downloading transcriptome from: {url}\")\n",
    "        try:\n",
    "            self.check_disk_space()\n",
    "            urllib.request.urlretrieve(url, self.fasta_gz)\n",
    "            self.logger.info(\"Download completed successfully\")\n",
    "            \n",
    "            file_size = os.path.getsize(self.fasta_gz)\n",
    "            self.logger.info(f\"Downloaded file size: {file_size/1024/1024:.2f} MB\")\n",
    "            \n",
    "            if file_size < 1000000:  # Less than 1MB\n",
    "                raise ValueError(f\"Downloaded file is too small ({file_size} bytes)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            if os.path.exists(self.fasta_gz):\n",
    "                os.remove(self.fasta_gz)\n",
    "            self.logger.error(f\"Failed to download transcriptome: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def decompress_fasta(self) -> None:\n",
    "        if os.path.exists(self.fasta):\n",
    "            self.logger.info(f\"Decompressed FASTA already exists: {self.fasta}\")\n",
    "            return\n",
    "\n",
    "        self.logger.info(\"Decompressing FASTA file...\")\n",
    "        try:\n",
    "            self.check_disk_space()\n",
    "            with gzip.open(self.fasta_gz, 'rb') as f_in:\n",
    "                with open(self.fasta, 'wb') as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            \n",
    "            compressed_size = os.path.getsize(self.fasta_gz)\n",
    "            decompressed_size = os.path.getsize(self.fasta)\n",
    "            self.logger.info(f\"Compressed size: {compressed_size/1024/1024:.2f} MB\")\n",
    "            self.logger.info(f\"Decompressed size: {decompressed_size/1024/1024:.2f} MB\")\n",
    "            \n",
    "            if not decompressed_size > compressed_size:\n",
    "                raise ValueError(\"Decompressed file is smaller than compressed file\")\n",
    "                \n",
    "            self.logger.info(\"Decompression completed successfully\")\n",
    "        except Exception as e:\n",
    "            if os.path.exists(self.fasta):\n",
    "                os.remove(self.fasta)\n",
    "            self.logger.error(f\"Failed to decompress FASTA: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def build_salmon_index(self, threads: int = 16, kmer_length: int = 31, timeout: int = 7200) -> None:\n",
    "        if os.path.exists(self.index_dir):\n",
    "            self.logger.info(f\"Removing existing index directory: {self.index_dir}\")\n",
    "            shutil.rmtree(self.index_dir)\n",
    "        \n",
    "        os.makedirs(self.index_dir, exist_ok=True)\n",
    "\n",
    "        # Add --keepDuplicates flag to handle short sequences better\n",
    "        cmd = [\n",
    "            \"salmon\", \"index\",\n",
    "            \"-t\", self.fasta,\n",
    "            \"-i\", self.index_dir,\n",
    "            \"-p\", str(threads),\n",
    "            \"--gencode\",\n",
    "            \"-k\", str(kmer_length),\n",
    "            \"--keepDuplicates\"  # Added this flag\n",
    "        ]\n",
    "\n",
    "        self.logger.info(\"Building Salmon index...\")\n",
    "        self.logger.info(f\"Command: {' '.join(cmd)}\")\n",
    "        \n",
    "        try:\n",
    "            self.check_disk_space()\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Create a file to collect warnings\n",
    "            warning_file = os.path.join(self.work_dir, \"salmon_index_warnings.log\")\n",
    "            \n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                text=True,\n",
    "                bufsize=1\n",
    "            )\n",
    "            \n",
    "            def is_warning(line: str) -> bool:\n",
    "                return (\n",
    "                    \"warning\" in line.lower() or\n",
    "                    \"had length less than equal to\" in line or\n",
    "                    \"Version Server Response\" in line\n",
    "                )\n",
    "\n",
    "            def is_progress(line: str) -> bool:\n",
    "                return any(x in line for x in [\n",
    "                    \"Round\", \"Pass\", \"junctions count\", \"Hash table\", \n",
    "                    \"Reallocating\", \"Threads\", \"Vertex length\"\n",
    "                ])\n",
    "\n",
    "            with open(warning_file, 'w') as warn_f:\n",
    "                while True:\n",
    "                    if time.time() - start_time > timeout:\n",
    "                        process.kill()\n",
    "                        raise TimeoutError(f\"Index building timed out after {timeout} seconds\")\n",
    "                    \n",
    "                    # Check if process has ended\n",
    "                    return_code = process.poll()\n",
    "                    if return_code is not None:\n",
    "                        remaining_stdout, remaining_stderr = process.communicate()\n",
    "                        if remaining_stdout:\n",
    "                            self.logger.info(remaining_stdout.strip())\n",
    "                        if remaining_stderr:\n",
    "                            for line in remaining_stderr.splitlines():\n",
    "                                if is_warning(line):\n",
    "                                    warn_f.write(f\"{line}\\n\")\n",
    "                                elif not is_progress(line):\n",
    "                                    self.logger.error(line.strip())\n",
    "                        break\n",
    "                        \n",
    "                    # Read output\n",
    "                    stdout_line = process.stdout.readline()\n",
    "                    stderr_line = process.stderr.readline()\n",
    "                    \n",
    "                    if stdout_line:\n",
    "                        if is_progress(stdout_line):\n",
    "                            self.logger.info(stdout_line.strip())\n",
    "                    \n",
    "                    if stderr_line:\n",
    "                        if is_warning(stderr_line):\n",
    "                            warn_f.write(f\"{stderr_line}\\n\")\n",
    "                        elif is_progress(stderr_line):\n",
    "                            self.logger.info(stderr_line.strip())\n",
    "                        else:\n",
    "                            self.logger.error(stderr_line.strip())\n",
    "                    \n",
    "                    time.sleep(0.1)\n",
    "            \n",
    "            build_time = time.time() - start_time\n",
    "            \n",
    "            if return_code != 0:\n",
    "                raise subprocess.CalledProcessError(\n",
    "                    return_code, \n",
    "                    cmd, \n",
    "                    output=None,\n",
    "                    stderr=\"Salmon index building failed\"\n",
    "                )\n",
    "            \n",
    "            # Count warnings\n",
    "            with open(warning_file) as f:\n",
    "                warning_count = sum(1 for _ in f)\n",
    "            \n",
    "            self.logger.info(f\"Salmon index built successfully in {build_time:.1f} seconds\")\n",
    "            self.logger.info(f\"Found {warning_count} warnings (saved to {warning_file})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error during index building: {str(e)}\")\n",
    "            if os.path.exists(self.index_dir):\n",
    "                shutil.rmtree(self.index_dir)\n",
    "            raise\n",
    "        finally:\n",
    "            if 'process' in locals() and process.poll() is None:\n",
    "                process.kill()\n",
    "\n",
    "        # Validate immediately after building\n",
    "        if not self.validate_index():\n",
    "            raise RuntimeError(\"Index validation failed after building\")\n",
    "\n",
    "    def validate_index(self) -> bool:\n",
    "        \"\"\"Validate the created Salmon index with updated file checks.\"\"\"\n",
    "        self.logger.info(\"Validating Salmon index...\")\n",
    "        \n",
    "        if not os.path.exists(self.index_dir):\n",
    "            self.logger.error(\"Index directory does not exist\")\n",
    "            return False\n",
    "\n",
    "        required_files = [\n",
    "            'complete_ref_lens.bin',\n",
    "            'ctable.bin',\n",
    "            'ctg_offsets.bin',\n",
    "            'duplicate_clusters.tsv',\n",
    "            'info.json',\n",
    "            'mphf.bin',\n",
    "            'pos.bin',\n",
    "            'pre_indexing.log',\n",
    "            'rank.bin',\n",
    "            'refseq.bin',\n",
    "            'seq.bin',\n",
    "            'versionInfo.json'\n",
    "        ]\n",
    "        \n",
    "        existing_files = os.listdir(self.index_dir)\n",
    "        self.logger.info(f\"Files in index directory: {existing_files}\")\n",
    "        \n",
    "        missing_files = [f for f in required_files \n",
    "                        if not os.path.exists(os.path.join(self.index_dir, f))]\n",
    "        \n",
    "        if missing_files:\n",
    "            self.logger.error(f\"Missing index files: {missing_files}\")\n",
    "            return False\n",
    "        \n",
    "        # Check file sizes\n",
    "        total_size = sum(os.path.getsize(os.path.join(self.index_dir, f)) for f in existing_files)\n",
    "        self.logger.info(f\"Total index size: {total_size/1024/1024:.2f} MB\")\n",
    "        \n",
    "        if total_size < 1000000:  # Less than 1MB\n",
    "            self.logger.error(\"Index files are suspiciously small\")\n",
    "            return False\n",
    "            \n",
    "        self.logger.info(\"Index validation successful\")\n",
    "        return True\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Clean up intermediate files.\"\"\"\n",
    "        self.logger.info(\"Cleaning up intermediate files...\")\n",
    "        \n",
    "        if os.path.exists(self.fasta):\n",
    "            os.remove(self.fasta)\n",
    "            self.logger.info(f\"Removed decompressed FASTA: {self.fasta}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    work_dir = \"/beegfs/scratch/ric.broccoli/kubacki.michal/SRF_Snords/salmon_index\"\n",
    "    gencode_version = \"v38\"\n",
    "    genome = \"human\"\n",
    "    threads = 16\n",
    "    \n",
    "    builder = SalmonIndexBuilder(work_dir, gencode_version, genome)\n",
    "    \n",
    "    try:\n",
    "        # Verify Salmon installation first\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\"salmon\", \"--version\"],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                check=True\n",
    "            )\n",
    "            builder.logger.info(f\"Salmon version: {result.stdout.strip()}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            raise RuntimeError(\"Salmon is not properly installed or not in PATH\")\n",
    "        \n",
    "        # Execute pipeline\n",
    "        builder.download_transcriptome()\n",
    "        builder.decompress_fasta()\n",
    "        builder.build_salmon_index(threads=threads, timeout=7200)  # 2 hour timeout\n",
    "        \n",
    "        print(f\"\\nSalmon index created successfully at: {builder.index_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError creating Salmon index: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        builder.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
